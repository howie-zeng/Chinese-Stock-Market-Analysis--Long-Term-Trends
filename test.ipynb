{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import model as m\n",
    "import data_processing as dp\n",
    "import feature_engineering as fe\n",
    "import make_plots as mp\n",
    "import parameters as p\n",
    "import evaluation as e\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "default_max_rows = pd.get_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading daily data from existing file.\n",
      "Loading monthly data from existing file.\n"
     ]
    }
   ],
   "source": [
    "assert len(p.missing_files) == 0\n",
    "merged_data_daily, merged_data_monthly = dp.data_loading(p.daily_files, p.monthly_files)\n",
    "merged_data_daily = dp.get_sector_data(merged_data_daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_daily, data_monthly = fe.feature_construction(merged_data_daily, merged_data_monthly)\n",
    "data_monthly_merged = dp.merge_daily_and_monthly_data(data_daily, data_monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2568 rows with more than 66.53888275111062% missing values.\n",
      "\n",
      "\n",
      "Increase in missing statistics for each column:\n",
      "beta_000905: 7.35%\n",
      "daily_ret_vol_roll_126: 0.48%\n",
      "return_daily: 0.00%\n",
      "total_market_value: 5.53%\n",
      "turnover_daily: 5.53%\n",
      "000905_close: 0.00%\n",
      "000905_return_daily: 0.00%\n",
      "000905_return_monthly: 0.44%\n",
      "maxret: 0.00%\n",
      "illiquidity_monthly: 1.01%\n",
      "mve_log: 6.66%\n",
      "return_monthly: 0.98%\n",
      "ret_vol_monthly: 0.98%\n",
      "std_dolvol_monthly: 1.01%\n",
      "std_turnover_monthly: 6.40%\n",
      "zero_trade_days: 1.25%\n",
      "chmom: 10.99%\n",
      "mom1m: 1.55%\n",
      "mom12m: 7.38%\n",
      "mom6m: 4.30%\n",
      "mom36m: 17.81%\n"
     ]
    }
   ],
   "source": [
    "data_monthly_imputed = dp.handle_crosssectional_na(data_monthly_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline MOdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 425857 rows, which is 17.73%.\n"
     ]
    }
   ],
   "source": [
    "data_monthly_nona = data_monthly_imputed.dropna()\n",
    "removed_percentage = (1 - len(data_monthly_nona) / len(data_monthly_imputed)) * 100\n",
    "print(f\"Removed {len(data_monthly_nona)} rows, which is {removed_percentage:.2f}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set range:\n",
      "2015-03-31 00:00:00 to 2021-05-31 00:00:00\n",
      "Validation set range:\n",
      "2021-05-31 00:00:00 to 2022-11-30 00:00:00\n",
      "Testing set range:\n",
      "2022-11-30 00:00:00 to 2024-03-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = m.split_train_val_test(data_monthly_nona, predictor=\"return_monthly\")\n",
    "input_dim=X_train.shape[1]\n",
    "\n",
    "print(\"Training set range:\")\n",
    "print(X_train.index.min(), \"to\", X_train.index.max())\n",
    "\n",
    "print(\"Validation set range:\")\n",
    "print(X_val.index.min(), \"to\", X_val.index.max())\n",
    "\n",
    "print(\"Testing set range:\")\n",
    "print(X_test.index.min(), \"to\", X_test.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLSModel\n",
      "OLS3Model\n",
      "PLSModel\n",
      "LASSOModel\n",
      "ElasticNetModel\n",
      "GBRTModel\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[345], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m model_class\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m model_name\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_name)\n\u001b[1;32m---> 24\u001b[0m model_fitted, scaler \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mtrain(X_train, y_train, model_class)\n\u001b[0;32m     25\u001b[0m validation_res \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mvalidation(X_val, model_fitted, scaler)\n\u001b[0;32m     26\u001b[0m r_2 \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mcalculate_r2_oos(validation_res, y_val\u001b[38;5;241m.\u001b[39mvalues)\n",
      "File \u001b[1;32mc:\\Users\\Howard\\OneDrive\\实习\\东方汇智\\Chinese-Stock-Market-Analysis--Long-Term-Trends\\model.py:209\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(X, y, model)\u001b[0m\n\u001b[0;32m    207\u001b[0m     X \u001b[38;5;241m=\u001b[39m X[p\u001b[38;5;241m.\u001b[39mols3_predictors]\n\u001b[0;32m    208\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m--> 209\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(scaler\u001b[38;5;241m.\u001b[39mfit_transform(X), y)\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, scaler\n",
      "File \u001b[1;32mc:\\Users\\Howard\\OneDrive\\实习\\东方汇智\\Chinese-Stock-Market-Analysis--Long-Term-Trends\\model.py:31\u001b[0m, in \u001b[0;36mBaseModel.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(X, y)\n",
      "File \u001b[1;32mc:\\Users\\Howard\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Howard\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:784\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[0;32m    783\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 784\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_stages(\n\u001b[0;32m    785\u001b[0m     X_train,\n\u001b[0;32m    786\u001b[0m     y_train,\n\u001b[0;32m    787\u001b[0m     raw_predictions,\n\u001b[0;32m    788\u001b[0m     sample_weight_train,\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng,\n\u001b[0;32m    790\u001b[0m     X_val,\n\u001b[0;32m    791\u001b[0m     y_val,\n\u001b[0;32m    792\u001b[0m     sample_weight_val,\n\u001b[0;32m    793\u001b[0m     begin_at_stage,\n\u001b[0;32m    794\u001b[0m     monitor,\n\u001b[0;32m    795\u001b[0m )\n\u001b[0;32m    797\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\Howard\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:880\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    873\u001b[0m         initial_loss \u001b[38;5;241m=\u001b[39m factor \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss(\n\u001b[0;32m    874\u001b[0m             y_true\u001b[38;5;241m=\u001b[39my_oob_masked,\n\u001b[0;32m    875\u001b[0m             raw_prediction\u001b[38;5;241m=\u001b[39mraw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    876\u001b[0m             sample_weight\u001b[38;5;241m=\u001b[39msample_weight_oob_masked,\n\u001b[0;32m    877\u001b[0m         )\n\u001b[0;32m    879\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 880\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_stage(\n\u001b[0;32m    881\u001b[0m     i,\n\u001b[0;32m    882\u001b[0m     X,\n\u001b[0;32m    883\u001b[0m     y,\n\u001b[0;32m    884\u001b[0m     raw_predictions,\n\u001b[0;32m    885\u001b[0m     sample_weight,\n\u001b[0;32m    886\u001b[0m     sample_mask,\n\u001b[0;32m    887\u001b[0m     random_state,\n\u001b[0;32m    888\u001b[0m     X_csc\u001b[38;5;241m=\u001b[39mX_csc,\n\u001b[0;32m    889\u001b[0m     X_csr\u001b[38;5;241m=\u001b[39mX_csr,\n\u001b[0;32m    890\u001b[0m )\n\u001b[0;32m    892\u001b[0m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32mc:\\Users\\Howard\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:490\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    487\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    489\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csc \u001b[38;5;28;01mif\u001b[39;00m X_csc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[1;32m--> 490\u001b[0m tree\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    491\u001b[0m     X, neg_g_view[:, k], sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    492\u001b[0m )\n\u001b[0;32m    494\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[0;32m    495\u001b[0m X_for_tree_update \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n",
      "File \u001b[1;32mc:\\Users\\Howard\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Howard\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1377\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1350\u001b[0m \n\u001b[0;32m   1351\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1377\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m   1378\u001b[0m         X,\n\u001b[0;32m   1379\u001b[0m         y,\n\u001b[0;32m   1380\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1381\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[0;32m   1382\u001b[0m     )\n\u001b[0;32m   1383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Howard\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_classes = [\n",
    "    m.OLSModel(),\n",
    "    m.OLS3Model(),\n",
    "    m.PLSModel(),\n",
    "    m.LASSOModel(),\n",
    "    m.ElasticNetModel(),\n",
    "    # m.GBRTModel(),\n",
    "    m.RFModel(),\n",
    "    m.XGBoostModel()\n",
    "]\n",
    "\n",
    "num_layers_range = range(1, 6)\n",
    "for num_layers in num_layers_range:\n",
    "    model_classes.append(m.NNModel(input_dim=input_dim, num_layers=num_layers))\n",
    "\n",
    "model_r_2 = {}\n",
    "models_fitted = {}\n",
    "model_res = pd.DataFrame()\n",
    "model_res.index = y_val.index\n",
    "for model_class in model_classes:\n",
    "    model_name = model_class.name if hasattr(model_class, \"name\") else model_class.__class__.__name__\n",
    "    model_class.name = model_name\n",
    "    print(model_name)\n",
    "    model_fitted, scaler = m.train(X_train, y_train, model_class)\n",
    "    validation_res = m.validation(X_val, model_fitted, scaler)\n",
    "    r_2 = e.calculate_r2_oos(validation_res, y_val.values)\n",
    "\n",
    "    models_fitted[model_name] = model_fitted\n",
    "    model_res[model_name] = validation_res\n",
    "    model_r_2[model_name] = r_2\n",
    "model_res['y'] = y_val\n",
    "for model_name, r_2 in model_r_2.items():\n",
    "    print(f\"{model_name}: {r_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_class in model_classes:\n",
    "    model_name = model_class.name if hasattr(model_class, \"name\") else model_class.__class__.__name__\n",
    "    print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_tune = [\n",
    "    m.OLSModel,\n",
    "    m.OLS3Model,\n",
    "    m.PLSModel,\n",
    "    m.LASSOModel,\n",
    "    m.ElasticNetModel,\n",
    "    m.GBRTModel,\n",
    "    m.RFModel,\n",
    "    m.XGBoostModel\n",
    "]\n",
    "best_trials = e.hyperparameter_tuning(X_train, y_train, X_val, y_val, models_to_tune, n_trials=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imputed = dp.fillnas_and_convert(data, dataOffset=\"Y\")\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = m.split_train_val_test(data_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.columns[:10]  \n",
    "importance_df, percentage_change_df = e.feathre_importance(model_classes, X_train, y_train, features=features, permutation_importance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.macroeconomic_feature_importance(percentage_change_df)\n",
    "sorted_df = mp.characteristic_feature_importance(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df.apply(lambda x: (x - x.min()) / (x.max() - x.min()), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "deciles  = e.sort_into_deciles(model_res['NNModel_nn4']['y_pred'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.form_portfolios(model_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
